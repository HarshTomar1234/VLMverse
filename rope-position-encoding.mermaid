graph TB
    subgraph "Rotary Position Encoding (RoPE)"
        A[Input: Query/Key vectors]
        B[Position encoding]
        C[Apply rotation matrix]
        D[Output: Position-aware vectors]
        
        A --> C
        B --> C
        C --> D
        
        style A fill:#f9f9f9,stroke:#333,stroke-width:1px
        style B fill:#f9f9f9,stroke:#333,stroke-width:1px
        style C fill:#e6f7ff,stroke:#333,stroke-width:1px
        style D fill:#f9f9f9,stroke:#333,stroke-width:1px
    end
    
    subgraph "Mathematical Formulation"
        E["Position m embedding in 2D plane:
        For each pair (q2j, q2j+1) in Q:
        Apply rotation matrix R_θ(m)"]
        
        F["Rotation Matrix R_θ(m):
        [cos(mθj)  -sin(mθj)]
        [sin(mθj)   cos(mθj)]
        where θj = 10000^(-2j/d)"]
        
        G["Full RoPE formulation:
        q̂m,2j   = qm,2j·cos(mθj) - qm,2j+1·sin(mθj)
        q̂m,2j+1 = qm,2j·sin(mθj) + qm,2j+1·cos(mθj)"]
        
        H["The complete matrix form:
        q̂m = Reℂ(e^(imθ) ⊙ q)
        where ⊙ is complex multiplication"]
        
        E --> F --> G --> H
        
        style E fill:#f0f0f0,stroke:#333,stroke-width:1px
        style F fill:#f0f0f0,stroke:#333,stroke-width:1px
        style G fill:#f0f0f0,stroke:#333,stroke-width:1px
        style H fill:#f0f0f0,stroke:#333,stroke-width:1px
    end
    
    subgraph "Key Properties"
        I["1. Relative position encoding 
        ⟨q̂m, k̂n⟩ = f(q, k, m-n)"]
        
        J["2. Decaying attention spans
        with frequency θj"]
        
        K["3. Linear extrapolation beyond
        training context length"]
        
        style I fill:#e6ffe6,stroke:#333,stroke-width:1px
        style J fill:#e6ffe6,stroke:#333,stroke-width:1px
        style K fill:#e6ffe6,stroke:#333,stroke-width:1px
    end
